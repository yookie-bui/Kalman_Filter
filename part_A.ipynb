{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SENSOR MODELS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IR 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "from matplotlib.pyplot import subplots, show"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load data\r\n",
    "# Sensor model\r\n",
    "filename = 'D:/428/assignment 1/enmt482-assignment1-source_code/partA/calibration.csv'\r\n",
    "data = np.loadtxt(filename, delimiter=',', skiprows=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Split into columns\r\n",
    "index, time, dist, velocity_command, raw_ir1, raw_ir2, raw_ir3, raw_ir4, \\\r\n",
    "    sonar1, sonar2 = data.T"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy.optimize import curve_fit\r\n",
    "\r\n",
    "# Define non linear sensor model\r\n",
    "def model(x, a, b, c, d):\r\n",
    "    return a + b/(x + c) + d*x\r\n",
    "\r\n",
    "params_ir3, cov = curve_fit(model, dist, raw_ir3)\r\n",
    "zfit_ir3 = model(dist, *params_ir3)\r\n",
    "zerror_ir3 = raw_ir3 - zfit_ir3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the dataset and its best fit line\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "plt.plot(dist,raw_ir3,'.',label='Data',alpha=0.2)\r\n",
    "plt.plot(dist,zfit_ir3,label='Fit')\r\n",
    "plt.grid()\r\n",
    "plt.xlabel('Range x')\r\n",
    "plt.ylabel('Voltage')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Error plot\r\n",
    "plt.plot(dist,zerror_ir3,'.', alpha=0.2)\r\n",
    "plt.grid()\r\n",
    "plt.xlabel('Range x')\r\n",
    "plt.ylabel('Measurement error v')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove outliers\r\n",
    "#ir1: [-0.3 0.3]\r\n",
    "#ir3: [-0.18 0.18]\r\n",
    "#ir4+2: [-0.4 0.4]\r\n",
    "#sonar1: [0 0.5]\r\n",
    "#sonar2: [-2.4 0.2]\r\n",
    "f_dist_ir3 = []\r\n",
    "f_data_ir3 = []\r\n",
    "f_dist_ir3 = np.array(f_dist_ir3, dtype=np.float64)\r\n",
    "f_data_ir3 = np.array(f_data_ir3, dtype=np.float64)\r\n",
    "for i in range(len(zerror_ir3)):\r\n",
    "    if zerror_ir3[i] < 0.2 and zerror_ir3[i] > -0.2:\r\n",
    "        f_dist_ir3 = np.append(f_dist_ir3, dist[i])\r\n",
    "        f_data_ir3 = np.append(f_data_ir3, raw_ir3[i])\r\n",
    "        \r\n",
    "f_params_ir3, cov = curve_fit(model, f_dist_ir3, f_data_ir3)\r\n",
    "f_zfit_ir3 = model(f_dist_ir3, *f_params_ir3)\r\n",
    "f_zerror_ir3 = f_data_ir3 - f_zfit_ir3\r\n",
    "\r\n",
    "plt.plot(f_dist_ir3,f_data_ir3,'.',label='Data',alpha=0.2)\r\n",
    "plt.plot(f_dist_ir3,f_zfit_ir3,label='Fit')\r\n",
    "plt.xlabel('Range x')\r\n",
    "plt.ylabel('Measurement z')\r\n",
    "plt.grid()\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(f_dist_ir3,f_zerror_ir3,'.',alpha=0.2)\r\n",
    "plt.xlabel('Range x')\r\n",
    "plt.ylabel('Measurement error v')\r\n",
    "plt.grid()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.hist(f_zerror_ir3, bins=40, density=True)\r\n",
    "plt.xlabel('Error v')\r\n",
    "plt.ylabel('Histogram')\r\n",
    "plt.grid()\r\n",
    "plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Fit Gaussian to histogram\r\n",
    "import scipy.stats as sstat\r\n",
    "from scipy.stats import norm\r\n",
    "import statistics as stat\r\n",
    "#Best fit\r\n",
    "(mu, sigma) = norm.fit(f_zerror_ir3)\r\n",
    "std = stat.stdev(f_zerror_ir3)\r\n",
    "n, bins, patches = plt.hist(f_zerror_ir3, bins=40, density=True)\r\n",
    "y = norm.pdf(bins, mu, sigma)\r\n",
    "plt.plot(bins, y, color='black',linewidth=2)\r\n",
    "plt.grid()\r\n",
    "plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IR 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fit the best fit line\r\n",
    "params_ir1, cov = curve_fit(model, dist, raw_ir1)\r\n",
    "zfit_ir1 = model(dist, *params_ir1)\r\n",
    "zerror_ir1 = raw_ir1 - zfit_ir1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the dataset with its best fit line\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "plt.plot(dist,raw_ir1,'.',label='Data',alpha=0.2)\r\n",
    "plt.plot(dist,zfit_ir1,label='Fit')\r\n",
    "plt.grid()\r\n",
    "plt.xlabel('Range x')\r\n",
    "plt.ylabel('Voltage')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot error\r\n",
    "plt.plot(dist,zerror_ir1,'.', alpha=0.2)\r\n",
    "plt.grid()\r\n",
    "plt.xlabel('Range x')\r\n",
    "plt.ylabel('Measurement error v')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove outliers\r\n",
    "#ir1: [-0.3 0.3]\r\n",
    "#ir3: [-0.18 0.18]\r\n",
    "#ir4+2: [-0.4 0.4]\r\n",
    "#sonar1: [0 0.5]\r\n",
    "#sonar2: [-2.4 0.2]\r\n",
    "f_dist_ir1 = []\r\n",
    "f_data_ir1 = []\r\n",
    "f_dist_ir1 = np.array(f_dist_ir1, dtype=np.float64)\r\n",
    "f_data_ir1 = np.array(f_data_ir1, dtype=np.float64)\r\n",
    "for i in range(len(zerror_ir1)):\r\n",
    "    if zerror_ir1[i] < 0.3 and zerror_ir1[i] > -0.3:\r\n",
    "        f_dist_ir1 = np.append(f_dist_ir1, dist[i])\r\n",
    "        f_data_ir1 = np.append(f_data_ir1, raw_ir1[i])\r\n",
    "        \r\n",
    "f_params_ir1, cov = curve_fit(model, f_dist_ir1, f_data_ir1)\r\n",
    "f_zfit_ir1 = model(f_dist_ir1, *f_params_ir1)\r\n",
    "f_zerror_ir1 = f_data_ir1- f_zfit_ir1\r\n",
    "\r\n",
    "plt.plot(f_dist_ir1,f_data_ir1,'.',label='Data',alpha=0.2)\r\n",
    "plt.plot(f_dist_ir1,f_zfit_ir1,label='Fit')\r\n",
    "plt.xlabel('Range x')\r\n",
    "plt.ylabel('Measurement z')\r\n",
    "plt.grid()\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(f_dist_ir1,f_zerror_ir1,'.',alpha=0.2)\r\n",
    "plt.xlabel('Range x')\r\n",
    "plt.ylabel('Measurement error v')\r\n",
    "plt.grid()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.hist(f_zerror_ir1, bins=40, density=True)\r\n",
    "plt.xlabel('Error v')\r\n",
    "plt.ylabel('Histogram')\r\n",
    "plt.grid()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Fit Gaussian to histogram\r\n",
    "import scipy.stats as sstat\r\n",
    "from scipy.stats import norm\r\n",
    "\r\n",
    "#Best fit\r\n",
    "(mu, sigma) = norm.fit(f_zerror_ir1)\r\n",
    "std = stat.stdev(f_zerror_ir1)\r\n",
    "n, bins, patches = plt.hist(f_zerror_ir1, bins=40, density=True)\r\n",
    "y = norm.pdf(bins, mu, sigma)\r\n",
    "plt.plot(bins, y, color='black',linewidth=2)\r\n",
    "plt.grid()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sonar 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fit the parametric mmodel\r\n",
    "coeff = np.polyfit(dist,sonar1, 9)\r\n",
    "fit = np.poly1d(coeff)\r\n",
    "\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "plt.plot(dist,sonar1,'.',label='Data',alpha=0.2)\r\n",
    "plt.plot(dist,fit(dist),label='Fit')\r\n",
    "plt.grid()\r\n",
    "plt.xlabel('Range x')\r\n",
    "plt.ylabel('Measurement z')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Error plot\r\n",
    "import statistics as stat\r\n",
    "error = sonar1 - fit(dist)\r\n",
    "mean = stat.mean(error)\r\n",
    "variance = stat.variance(error)\r\n",
    "\r\n",
    "plt.plot(dist,error,'.', alpha=0.2)\r\n",
    "plt.grid()\r\n",
    "plt.xlabel('Range x')\r\n",
    "plt.ylabel('Measurement error v')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove outliers\r\n",
    "#ir1: [-0.3 0.3]\r\n",
    "#ir3: [-0.18 0.18]\r\n",
    "#ir4+2: [-0.4 0.4]\r\n",
    "#sonar1: [0 0.5]\r\n",
    "#sonar2: [-2.4 0.2]\r\n",
    "f_dist_s1 = []\r\n",
    "f_data_s1 = []\r\n",
    "for i in range(len(error)):\r\n",
    "    if error[i] < 0.5 and error[i] > 0:\r\n",
    "        f_dist_s1.append(dist[i])\r\n",
    "        f_data_s1.append(sonar1[i])\r\n",
    "\r\n",
    "new_coeff = np.polyfit(f_dist_s1,f_data_s1, 2)\r\n",
    "new_fit = np.poly1d(new_coeff)\r\n",
    "\r\n",
    "plt.plot(f_dist_s1,f_data_s1,'.',label='Data',alpha=0.2)\r\n",
    "plt.plot(f_dist_s1,new_fit(f_dist_s1),label='Fit')\r\n",
    "plt.xlabel('Range x')\r\n",
    "plt.ylabel('Measurement z')\r\n",
    "plt.grid()\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "f_error_s1 = f_data_s1 - new_fit(f_dist_s1)\r\n",
    "new_mean = stat.mean(f_error_s1)\r\n",
    "new_variance = stat.variance(f_error_s1)\r\n",
    "\r\n",
    "# Remove outliers second time\r\n",
    "ff_dist_s1 = []\r\n",
    "ff_data_s1 = []\r\n",
    "for i in range(len(f_error_s1)):\r\n",
    "    #sonar1: >-0.03\r\n",
    "    #sonar2: <1\r\n",
    "    if f_error_s1[i] >-0.03:       \r\n",
    "        ff_dist_s1.append(f_dist_s1[i])\r\n",
    "        ff_data_s1.append(f_data_s1[i])\r\n",
    "\r\n",
    "f_params = np.polyfit(ff_dist_s1,ff_data_s1, 2)\r\n",
    "f_fit = np.poly1d(f_params)\r\n",
    "\r\n",
    "plt.plot(ff_dist_s1,ff_data_s1,'.',label='Data', alpha=0.2)\r\n",
    "plt.plot(ff_dist_s1,f_fit(ff_dist_s1),label='Fit')\r\n",
    "plt.legend()\r\n",
    "plt.grid()\r\n",
    "plt.xlabel('Range x')\r\n",
    "plt.ylabel('Measurement z')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ff_error_s1 = ff_data_s1 - f_fit(ff_dist_s1)\r\n",
    "ff_mean_s1 = stat.mean(ff_error_s1)\r\n",
    "ff_variance_s1 = stat.variance(ff_error_s1)\r\n",
    "plt.plot(ff_dist_s1,ff_error_s1,'.',alpha=0.2)\r\n",
    "plt.grid()\r\n",
    "plt.ylim(bottom=-0.02, top=0.04)\r\n",
    "plt.xlabel('Range x')\r\n",
    "plt.ylabel('Measurement error v')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.hist(ff_error_s1, bins=100, density=True)\r\n",
    "plt.xlim(left=-0.04, right=0.04)\r\n",
    "plt.xlabel('Error v')\r\n",
    "plt.ylabel('Histogram')\r\n",
    "plt.grid()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Fit Gaussian to histogram\r\n",
    "import scipy.stats as sstat\r\n",
    "from scipy.stats import norm\r\n",
    "\r\n",
    "#Best fit\r\n",
    "(mu, sigma) = norm.fit(ff_error_s1)\r\n",
    "std = stat.stdev(ff_error_s1)\r\n",
    "n, bins, patches = plt.hist(ff_error_s1, bins=100, density=True)\r\n",
    "y = norm.pdf(bins, mu, sigma)\r\n",
    "plt.plot(bins, y, color='black',linewidth=2)\r\n",
    "plt.grid()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SENSOR FUSION"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filename = 'D:/428/assignment 1/enmt482-assignment1-source_code/partA/training1.csv'\r\n",
    "data = np.loadtxt(filename, delimiter=',', skiprows=1)\r\n",
    "\r\n",
    "# Split into columns (for training1.cvs and training2.csv)\r\n",
    "index, time, dist, velocity_command, raw_ir1, raw_ir2, raw_ir3, raw_ir4, \\\r\n",
    "  sonar1, sonar2 = data.T\r\n",
    "\r\n",
    "# Split into columns (for test.cvs)\r\n",
    "#index, time, velocity_command, raw_ir1, raw_ir2, raw_ir3, raw_ir4, \\\r\n",
    "#   sonar1, sonar2 = data.T"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IR3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Test the sensor model\r\n",
    "a = f_params_ir3[0]\r\n",
    "b = f_params_ir3[1]\r\n",
    "c = f_params_ir3[2]\r\n",
    "d = f_params_ir3[3] \r\n",
    "\r\n",
    "# Define non linear function\r\n",
    "def test_func(x):\r\n",
    "    return a + b/(x+c) + d*x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "z_val_ir3 = []\r\n",
    "z_val_ir3 = np.array(z_val_ir3, dtype=np.float64)\r\n",
    "for i in range (len(raw_ir3)):\r\n",
    "    z_ir3= test_func(dist[i])\r\n",
    "    z_val_ir3 = np.append(z_val_ir3, z_ir3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#plt.plot(dist, z_val_ir3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Create inverse function of h(x)\r\n",
    "from __future__ import print_function\r\n",
    "import sympy as sy\r\n",
    "from sympy import *\r\n",
    "y, x, a, b, c, d = sy.symbols('y x a b c d', real=True)\r\n",
    "\r\n",
    "#Define equation\r\n",
    "fwd_equation = sy.Eq(y, a + b/(c+x) + d*x)\r\n",
    "\r\n",
    "#Inverse equation\r\n",
    "inverse = sy.solve(fwd_equation, x)\r\n",
    "print('found {} solutions for x:'.format(len(inverse)))\r\n",
    "print('\\n'.join([str(s) for s in inverse]))\r\n",
    "print('x = ', sy.latex(inverse[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Inverse function for IR__ sensor\r\n",
    "# Just need to change parameters corresponding to the chosen sensor\r\n",
    "a = f_params_ir3[0]\r\n",
    "b = f_params_ir3[1]\r\n",
    "c = f_params_ir3[2]\r\n",
    "d = f_params_ir3[3]\r\n",
    "\r\n",
    "# Define inverse function\r\n",
    "def inv_ir(z):\r\n",
    "    return (-a -c*d + z - sy.sqrt(a**2 - 2*a*c*d - 2*a*z - 4*b*d + c**2*d**2 + 2*c*d*z + z**2))/(2*d)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create x_hat values based on noiseless z values\r\n",
    "x_hat_ir3 = []\r\n",
    "x_hat_ir3 = np.array(x_hat_ir3, dtype=np.float64)\r\n",
    "for i in range(len(z_val_ir3)):\r\n",
    "    x_hat_val_ir3 = inv_ir(z_val_ir3[i])\r\n",
    "    x_hat_ir3 = np.append(x_hat_ir3, x_hat_val_ir3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the inverse function\r\n",
    "plt.plot(z_val_ir3, x_hat_ir3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Function to calculate standard deviation and variance by window\r\n",
    "def stats_calc(data, dist, window):\r\n",
    "    lower = 0\r\n",
    "    stdev_noise = []\r\n",
    "    upper = []\r\n",
    "    pos= []\r\n",
    "    var_noise = []\r\n",
    "    n_data = len(data)\r\n",
    "    while lower <= n_data:\r\n",
    "        if lower + window < n_data:\r\n",
    "            total = 0\r\n",
    "            mean = sum(data[lower: lower+window])/len(data[lower:lower+window])\r\n",
    "            for value in data[lower: lower+window]:\r\n",
    "                total += (value - mean)**2\r\n",
    "            stdev_noise += [(total/(len(data[lower:lower+window])-1))**0.5]\r\n",
    "            upper += [lower+window]\r\n",
    "        else:\r\n",
    "            total = 0\r\n",
    "            for value in data[lower:n_data]:\r\n",
    "                mean = sum(data[lower:n_data])/len(data[lower:n_data])\r\n",
    "                total += (value - mean)**2\r\n",
    "            stdev_noise += [(total/(len(data[lower:+n_data])-1))**0.5]\r\n",
    "            upper += [n_data]\r\n",
    "        lower += window\r\n",
    "\r\n",
    "    for i in range (len(upper)):\r\n",
    "        pos.append(dist[upper[i]-1])\r\n",
    "\r\n",
    "    for i in range (len(stdev_noise)):\r\n",
    "        var_noise.append(stdev_noise[i] ** 2)\r\n",
    "    \r\n",
    "    return (stdev_noise, var_noise, pos)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate standard deviation and variance by window\r\n",
    "stdev_noise_ir3 = []\r\n",
    "var_noise_ir3 = []\r\n",
    "pos_ir3 = []\r\n",
    "stdev_noise_ir3, var_noise_ir3, pos_ir3 = stats_calc(f_data_ir3, f_dist_ir3,window=20)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot variance and standard deviation\r\n",
    "plt.plot(pos_ir3, stdev_noise_ir3)\r\n",
    "plt.plot(pos_ir3, var_noise_ir3)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert noise variance to x_hat variance. Linearize model  \r\n",
    "h = a + b/(c+x) + d*x   #function h(n)\r\n",
    "diff_h = lambdify(x,h)  #inverse of function h(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate x_hat variance\r\n",
    "est_var_ir3 = []\r\n",
    "\r\n",
    "for i in range (len(pos_ir3)):  \r\n",
    "    diff = diff_h(pos_ir3[i])\r\n",
    "    n_var = var_noise_ir3[i] / (diff ** 2)\r\n",
    "    est_var_ir3.append(n_var) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot x_hat variance versus position\r\n",
    "plt.plot(pos_ir3, est_var_ir3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IR1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Test sensor model\r\n",
    "a = f_params_ir1[0]\r\n",
    "b = f_params_ir1[1]\r\n",
    "c = f_params_ir1[2]\r\n",
    "d = f_params_ir1[3]\r\n",
    "\r\n",
    "z_val_ir1 = []\r\n",
    "z_val_ir1 = np.array(z_val_ir1, dtype=np.float64)\r\n",
    "for i in range (len(raw_ir1)):\r\n",
    "    z_ir1 = test_func(dist[i])\r\n",
    "    z_val_ir1 = np.append(z_val_ir1, z_ir1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#plt.plot(dist, z_val_ir1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Test inervse function. Create x_hat values from noiseless z values\r\n",
    "x_hat_ir1 = []\r\n",
    "x_hat_ir1 = np.array(x_hat_ir1, dtype=np.float64)\r\n",
    "for i in range(len(z_val_ir1)):\r\n",
    "    x_hat_val_ir1 = inv_ir(z_val_ir1[i])\r\n",
    "    x_hat_ir1 = np.append(x_hat_ir1, x_hat_val_ir1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(z_val_ir1, x_hat_ir1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate noise variance and standard deviation by window method\r\n",
    "stdev_noise_ir1 = []\r\n",
    "var_noise_ir1 = []\r\n",
    "pos_ir1 = []\r\n",
    "stdev_noise_ir1, var_noise_ir1, pos_ir1 = stats_calc(f_data_ir1, f_dist_ir1, window=20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(pos_ir1, stdev_noise_ir1)\r\n",
    "plt.plot(pos_ir1, var_noise_ir1)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert noise variance to x_hat variance. Linearlize sensor model\r\n",
    "est_var_ir1 = []\r\n",
    "\r\n",
    "for i in range (len(pos_ir1)):  \r\n",
    "    diff = diff_h(pos_ir1[i])\r\n",
    "    n_var = var_noise_ir1[i] / (diff ** 2)\r\n",
    "    est_var_ir1.append(n_var) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(pos_ir1, est_var_ir1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sonar 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Test sensor model\r\n",
    "a = f_params[0]\r\n",
    "b = f_params[1]\r\n",
    "c = f_params[2]\r\n",
    "\r\n",
    "# Define function of linear model\r\n",
    "def s1_test_func(x):  \r\n",
    "    return a*x**2 + b*x + c "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "z_val_s1 = []\r\n",
    "z_val_s1 = np.array(z_val_s1, dtype=np.float64)\r\n",
    "for i in range (len(sonar1)):\r\n",
    "    z = s1_test_func(dist[i])\r\n",
    "    z_val_s1 = np.append(z_val_s1, z)\r\n",
    "\r\n",
    "#plt.plot(dist, z_val_s1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate inverse function for linear model\r\n",
    "# Define equation\r\n",
    "fwd_equation_s1 = sy.Eq(y, a*x**2 + b*x + c)\r\n",
    "\r\n",
    "# Inverse equation\r\n",
    "inverse_s1 = sy.solve(fwd_equation_s1, x)\r\n",
    "print('found {} solutions for x:'.format(len(inverse_s1)))\r\n",
    "print('\\n'.join([str(s) for s in inverse]))\r\n",
    "print('x = ', sy.latex(inverse[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Test inverse function of linear model\r\n",
    "a = f_params[0]\r\n",
    "b = f_params[1]\r\n",
    "c = f_params[2]\r\n",
    "\r\n",
    "# Define inverse function of linear model\r\n",
    "def inv_s1(z):\r\n",
    "    return (-b + sy.sqrt(-4*a*c + 4*a*z + b**2))/(2*a)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate x_hat values\r\n",
    "x_hat_s1 = []\r\n",
    "x_hat_s1 = np.array(x_hat_s1, dtype=np.float64)\r\n",
    "for i in range(len(sonar1)):\r\n",
    "    x_hat_val_s1 = inv_s1(sonar1[i])\r\n",
    "    x_hat_s1 = np.append(x_hat_s1, x_hat_val_s1)\r\n",
    "\r\n",
    "plt.plot(sonar1, x_hat_s1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate noise variance of h(x)\r\n",
    "# x_hat variance is assumed to be equal to noise variance\r\n",
    "stdev_noise_s1 = []\r\n",
    "var_noise_s1 = []\r\n",
    "pos_s1 = []\r\n",
    "stdev_noise_s1, var_noise_s1, pos_s1 = stats_calc(ff_data_s1, ff_dist_s1, window=20)\r\n",
    "\r\n",
    "plt.plot(pos_s1, stdev_noise_s1)\r\n",
    "plt.plot(pos_s1, var_noise_s1)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MOTION MODEL"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define function g(x)\r\n",
    "def motion_model(v_command, deltaT): \r\n",
    "    return v_command*deltaT\r\n",
    "\r\n",
    "# Define motion model\r\n",
    "def X_now(prior_pos, v_command, deltaT):\r\n",
    "    return prior_pos + motion_model(v_command, deltaT)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Estimated range from motion model only\r\n",
    "dt = 0.06\r\n",
    "pos_mm = []\r\n",
    "pos_mm = np.array(pos_mm, dtype=np.float64)\r\n",
    "pos_mm = np.append(pos_mm, 0)\r\n",
    "for i in range (1, len(velocity_command)):\r\n",
    "    next_p = X_now(pos_mm[i-1], velocity_command[i-1], dt)\r\n",
    "    pos_mm = np.append(pos_mm, next_p)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#plt.plot(time, pos_mm, label = 'Estimated Range')\r\n",
    "#plt.plot(time, dist, '--', label = 'True Range')\r\n",
    "#plt.legend()\r\n",
    "#plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Motion model noise variance and standard deviation\r\n",
    "stdev_noise_mm = []\r\n",
    "var_noise_mm = []\r\n",
    "fpos_mm = []\r\n",
    "stdev_noise_mm, var_noise_mm, fpos_mm = stats_calc(pos_mm, dist, window=20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Determine index of the x_hat variance value in the x_hat variance array based on the provided x_hat value \r\n",
    "def findIndex(x_hat, pos_array):\r\n",
    "    for i in range (len(pos_array)):\r\n",
    "        if x_hat < pos_array[i]:\r\n",
    "            return i\r\n",
    "        elif x_hat > pos_array[-1]:\r\n",
    "            return len(pos_array) - 1\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# KALMAN FILTER"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_est = []\r\n",
    "x_est = np.array(x_est, dtype=np.float64)\r\n",
    "x_est = np.append(x_est, 0)\r\n",
    "\r\n",
    "x_post = []\r\n",
    "x_post = np.array(x_post, dtype=np.float64)\r\n",
    "x_post = np.append(x_post, 0)\r\n",
    "tooFar = 0.3  #use to remove outliers\r\n",
    "dt = 0.06\r\n",
    "current_pos = 0 #for sensor models only\r\n",
    "K = 1\r\n",
    "#K = 0.8   #for training_.csv to avoid bias\r\n",
    "K_array = []\r\n",
    "K_array = np.array(K_array, dtype=np.float64)\r\n",
    "K_array = np.append(K_array, K)\r\n",
    "x_hat_pos = 0\r\n",
    "\r\n",
    "var_ff = []\r\n",
    "var_ff = np.array(var_ff, dtype=np.float64)\r\n",
    "var_ff = np.append(var_ff, 0)\r\n",
    "for i in range(1, len(time)):\r\n",
    "    topsum = 0\r\n",
    "    totalVar = 0\r\n",
    "    est_x = X_now(x_est[i-1], velocity_command[i-1], dt)\r\n",
    "    #p_minus = 0.00007  #for training_.cvs file to avoid bias\r\n",
    "    p_minus = var_noise_mm[findIndex(est_x, fpos_mm)]\r\n",
    "\r\n",
    "    #IR 1\r\n",
    "    x1_hat = inv_ir(raw_ir1[i])\r\n",
    "    if x1_hat.is_real:\r\n",
    "        if(np.abs(current_pos - x1_hat) < tooFar):   #if not satisfy, treat as outlier\r\n",
    "            var_ir1 = est_var_ir1[findIndex(x1_hat, pos_ir1)]\r\n",
    "            topsum += x1_hat/var_ir1\r\n",
    "            totalVar += 1/var_ir1\r\n",
    "    #IR 3\r\n",
    "    x2_hat = inv_ir(raw_ir3[i])\r\n",
    "    if x2_hat.is_real:\r\n",
    "        if(np.abs(current_pos - x2_hat) < tooFar):   #if not satisfy, treat as outlier\r\n",
    "            var_ir3 = est_var_ir3[findIndex(x2_hat, pos_ir3)]\r\n",
    "            topsum += x2_hat/var_ir3\r\n",
    "            totalVar += 1/var_ir3\r\n",
    "            \r\n",
    "    #Sonar 1\r\n",
    "    x3_hat = inv_s1(sonar1[i])\r\n",
    "    if(np.abs(current_pos - x3_hat) < tooFar):      #if not satisfy, treat as outlier\r\n",
    "        var_s1 = var_noise_s1[findIndex(x3_hat, pos_s1)]\r\n",
    "        topsum += x3_hat/var_s1\r\n",
    "        totalVar += 1/var_s1\r\n",
    "        \r\n",
    "\r\n",
    "\r\n",
    "    if totalVar != 0:\r\n",
    "        x_hat_pos = topsum/totalVar  #estimated postion\r\n",
    "        current_pos = x_hat_pos      #Use to compare with the next x_hat values to reject the outliers from sensor data\r\n",
    "        p_plus = 1/totalVar\r\n",
    "        if p_plus != 0.0000 and p_minus != 0.0000:\r\n",
    "            K = (1/p_plus) / (1/p_plus + 1/p_minus)    #Update Kalman gain\r\n",
    "            #v = 1/((1/p_plus) + (1/p_minus))           #Posterior variance\r\n",
    "            \r\n",
    "            \r\n",
    "    K_array = np.append(K_array, K)\r\n",
    "    #var_ff = np.append(var_ff,v)\r\n",
    "    x_final = (1-K)*x_hat_pos + (K)*est_x\r\n",
    "    x_est = np.append(x_est, x_final)\r\n",
    "    x_post = np.append(x_post, x_final)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Calculated the predicted range from motion model only \r\n",
    "m_pos = []\r\n",
    "m_pos = np.array(m_pos, dtype=np.float64)\r\n",
    "m_pos = np.append(m_pos, 0)\r\n",
    "for i in range(1, len(time)):\r\n",
    "    c_pos = X_now(m_pos[i-1], velocity_command[i-1], dt)\r\n",
    "    m_pos = np.append(m_pos, c_pos)\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Estimated range from Kalman filter\r\n",
    "new_post = np.array(x_post, dtype=np.int)\r\n",
    "std_v = np.std(new_post)\r\n",
    "plt.plot(time, x_post, label='Estimated range')\r\n",
    "plt.plot(time, m_pos, \"--\")\r\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc=\"center right\", borderaxespad=0.)\r\n",
    "plt.legend()\r\n",
    "plt.title(r'$\\sigma^{2} = %.5f$' % std_v)\r\n",
    "plt.show()\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Kalman gain versus time\r\n",
    "plt.plot(time, K_array,\".\", label='Kalman gain', alpha = 0.2)\r\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=\"center right\", borderaxespad=0.)\r\n",
    "plt.show()\r\n",
    "print(len(K_array))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Estimated range from Kalman filter vs True range (training_.csv only)\r\n",
    "plt.plot(time, x_post, label='Estimated range')\r\n",
    "plt.plot(time, dist, '--', label='True range')\r\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=\"center right\", borderaxespad=0.)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "fd67a53bfb281a2b2d1f1999d904b73d836732c7f3b40a4d2de14bd431148971"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}